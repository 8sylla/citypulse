# ðŸ™ï¸ CityPulse - Smart City Real-Time Analytics & ML

[![Scala](https://img.shields.io/badge/Scala-2.12-red.svg?logo=scala)](https://www.scala-lang.org/)
[![Spark](https://img.shields.io/badge/Spark-3.3.0-orange.svg?logo=apachespark)](https://spark.apache.org/)
[![Kafka](https://img.shields.io/badge/Kafka-KRaft-black.svg?logo=apachekafka)](https://kafka.apache.org/)
[![Cassandra](https://img.shields.io/badge/Cassandra-4.1-blue.svg?logo=apachecassandra)](https://cassandra.apache.org/)
[![Machine Learning](https://img.shields.io/badge/Spark-MLlib-brightgreen.svg)](https://spark.apache.org/mllib/)
[![License](https://img.s.io/badge/License-MIT-green.svg)](LICENSE)

> **Plateforme Big Data End-to-End** intÃ©grant ingestion IoT, traitement distribuÃ© en temps rÃ©el, stockage hybride et **Machine Learning** pour la prÃ©diction de pollution urbaine.

---
**Dashboard Grafana:**
![Dashboard Demo](demo-video.gif)
---

## ðŸŽ¯ Vue d'ensemble

**CityPulse** est une rÃ©ponse technologique aux dÃ©fis de gestion urbaine. La plateforme simule et ingÃ¨re des flux de donnÃ©es IoT (Trafic & Pollution) pour fournir une vision 360Â° de la ville.

Elle implÃ©mente une **Architecture Lambda ModernisÃ©e** capable de :
1.  **IngÃ©rer** des flux Ã  haute frÃ©quence via Kafka.
2.  **Historiser** les donnÃ©es brutes et nettoyÃ©es (Data Lake HDFS).
3.  **EntraÃ®ner** un modÃ¨le d'Intelligence Artificielle sur l'historique (Batch).
4.  **PrÃ©dire & Alerter** en temps rÃ©el sur les niveaux de pollution futurs (Streaming).

### Intelligence Artificielle & Logique MÃ©tier
Le systÃ¨me utilise **Spark MLlib** (RÃ©gression LinÃ©aire) pour prÃ©dire le taux de PM2.5 en fonction de la densitÃ© du trafic.

**RÃ¨gle d'Alerting Temps RÃ©el :**
```sql
IF (Pollution_Predict > 80 Âµg/mÂ³ AND DensitÃ©_Trafic > 40) 
THEN ALERTE = 'CRITIQUE'
ELSE IF (Pollution_Predict > 50 Âµg/mÂ³) 
THEN ALERTE = 'WARNING'
ELSE ALERTE = 'NORMAL'
```

---

## Architecture Technique

```mermaid
graph LR
    subgraph IoT Source
    A[Node-RED] -->|JSON Stream| B(Kafka KRaft)
    end

    subgraph "Speed Layer (Temps RÃ©el)"
    B -->|Subscribe| C{Spark Streaming Gold}
    E[ModÃ¨le ML HDFS] -.->|Load Model| C
    C -->|KPIs + PrÃ©dictions| F[(Cassandra)]
    end
    
    subgraph "Batch Layer (Historique & ML)"
    B -->|Subscribe| D[Spark Streaming Silver]
    D -->|Parquet| G[(HDFS Data Lake)]
    G -->|Train Data| H[Spark ML Training]
    H -->|Save Model| E
    end

    subgraph Viz
    F --> I[Grafana Dashboard]
    end
```

---

## ðŸ› ï¸ Stack Technique

| Domaine | Technologie | Version | RÃ´le |
|---------|-------------|---------|------|
| **`Ingestion`** | **Apache Kafka** | 7.6 (KRaft) | Bus d'Ã©vÃ©nements haute performance (No Zookeeper) |
| **`Simulation`** | **Node-RED** | 3.1 | GÃ©nÃ©rateur de trafic IoT rÃ©aliste |
| **`Compute`** | **Apache Spark** | 3.3.0 | Moteur unifiÃ© pour Streaming et Batch ML |
| **`ML Engine`** | **Spark MLlib** | 3.3.0 | Algorithme de RÃ©gression LinÃ©aire DistribuÃ© |
| **`Stockage Froid`** | **Hadoop HDFS** | 3.2.1 | Data Lake (Format Parquet partitionnÃ©) |
| **`Stockage Chaud`** | **Cassandra** | 4.1 | Base NoSQL Time-Series pour le temps rÃ©el |
| **`Visualisation`** | **Grafana** | Latest | Tableau de bord dÃ©cisionnel |
| **`Infra`** | **Docker** | 24+ | DÃ©ploiement "Infrastructure as Code" |

---

## Installation & DÃ©marrage

### 1. PrÃ©requis
*   Docker Desktop (Linux/Windows WSL2/Mac).
*   4 Go de RAM dÃ©diÃ©s Ã  Docker minimum.

### 2. DÃ©marrage de l'Infrastructure
```bash
git clone https://github.com/8sylla/citypulse.git
cd citypulse

# Lancer le cluster complet (Kafka, Spark Master+Workers, HDFS, Cassandra...)
docker-compose up -d
```

### 3. Initialisation des Ressources
Une fois les conteneurs actifs (vÃ©rifier via `docker ps`), initialisez les bases de donnÃ©es :

```bash
# 1. CrÃ©ation Topics Kafka
docker exec citypulse-kafka kafka-topics --create --topic traffic-raw --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1

docker exec citypulse-kafka kafka-topics --create --topic pollution-raw --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1

# 2. CrÃ©ation Table Cassandra (Avec colonne prÃ©diction ML)
docker exec -it citypulse-cassandra cqlsh -e "
  CREATE KEYSPACE IF NOT EXISTS citypulse WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1};
  USE citypulse;
  CREATE TABLE district_stats (
      district text, window_end timestamp, avg_speed double, max_density int, 
      avg_pm25 double, predicted_pm25 double, alert_level text,
      PRIMARY KEY (district, window_end)
  ) WITH CLUSTERING ORDER BY (window_end DESC);"

# 3. Structure HDFS
docker exec citypulse-namenode hdfs dfs -mkdir -p /data/silver /models
```

---

## â–¶ï¸ ExÃ©cution du Pipeline (De A Ã  Z)

### Ã‰tape 1 : Activer la Source IoT
1.  Ouvrez **Node-RED** : [http://localhost:1880](http://localhost:1880)
2.  Importez le flux `node-red/flows.json`.
3.  Cliquez sur **Deploy** et activez les injecteurs pour simuler le trafic.

### Ã‰tape 2 : Compilation & DÃ©ploiement
Compilez le code Scala en un "Fat JAR" et envoyez-le au cluster Spark.
```bash
sbt clean assembly
docker cp target/scala-2.12/CityPulse-assembly-1.0.jar citypulse-spark-master:/tmp/app.jar
```

### Ã‰tape 3 : GÃ©nÃ©ration de l'Historique (Silver Layer)
Nous devons d'abord accumuler des donnÃ©es pour entraÃ®ner l'IA.
```bash
docker exec -d citypulse-spark-master /spark/bin/spark-submit \
  --class citypulse.SilverProcessing \
  --master spark://citypulse-spark-master:7077 \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0 \
  /tmp/app.jar
```
*â³ Laissez tourner 5 Ã  10 minutes pour remplir le Data Lake.*

### Ã‰tape 4 : EntraÃ®nement du ModÃ¨le IA (Batch)
Une fois les donnÃ©es suffisantes, nous entraÃ®nons le modÃ¨le de prÃ©diction.
```bash
docker exec -it citypulse-spark-master /spark/bin/spark-submit \
  --class citypulse.ModelTraining \
  --master spark://citypulse-spark-master:7077 \
  /tmp/app.jar
```
*SuccÃ¨s si : `>>> MODÃˆLE ENTRAINÃ‰ ET SAUVEGARDÃ‰ ! <<<`*

### Ã‰tape 5 : Lancement du Temps RÃ©el + PrÃ©dictions (Gold Layer)
Le job final qui lit Kafka, charge le modÃ¨le IA, prÃ©dit et Ã©crit dans Cassandra.

```bash
docker exec -it citypulse-spark-master /spark/bin/spark-submit \
  --class citypulse.GoldAggregations \
  --master spark://citypulse-spark-master:7077 \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0,com.datastax.spark:spark-cassandra-connector_2.12:3.3.0 \
  --conf spark.cassandra.connection.host=citypulse-cassandra \
  --conf spark.sql.shuffle.partitions=3 \
  /tmp/app.jar
```

---

## Visualisation (Grafana)

1.  AccÃ©dez Ã  [http://localhost:3000](http://localhost:3000) (Login: `admin` / `citypulse`).
2.  Configurez la Datasource Cassandra (`citypulse-cassandra:9042`).
3.  CrÃ©ez un dashboard avec la requÃªte suivante pour comparer RÃ©alitÃ© vs IA :

```sql
SELECT window_end, avg_pm25, predicted_pm25 
FROM district_stats 
WHERE district = 'Centre' 
ALLOW FILTERING
```

**RÃ©sultat :**
![Dashboard Demo](image.png)

---

## ðŸ“ Structure du Projet

```bash
citypulse/
â”œâ”€â”€ docker-compose.yml           # Orchestration complÃ¨te
â”œâ”€â”€ src/main/scala/citypulse/
â”‚   â”œâ”€â”€ SilverProcessing.scala   # Ingestion & Stockage (Batch Layer Prep)
â”‚   â”œâ”€â”€ ModelTraining.scala      # Machine Learning (Spark MLlib)
â”‚   â””â”€â”€ GoldAggregations.scala   # Streaming + Inference + Cassandra
â”œâ”€â”€ build.sbt                    # DÃ©pendances (Spark SQL, Streaming, ML, Kafka)
â”œâ”€â”€ node-red/flows.json          # Simulation IoT
â””â”€â”€ README.md                    # Documentation
```

---

## ðŸ‘¨â€ðŸ’» Auteur

**SYLLA N'faly**  
*Ã‰lÃ¨ve IngÃ©nieur - PassionnÃ© par le Data Engineering & Big Data*  
Projet rÃ©alisÃ© dans le cadre d'un module acadÃ©mique avancÃ©.

